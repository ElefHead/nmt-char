{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from nmt.datasets import Vocab, VocabStore\n",
    "from nmt.datasets import batch_iter\n",
    "from nmt.networks import CharEmbedding\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup something to work with\n",
    "\n",
    "sentences = [\n",
    "    \"Human: What do we want?\",\n",
    "    \"Computer: Natural language processing!\",\n",
    "    \"Human: When do we want it?\",\n",
    "    \"Computer: When do we want what?\"\n",
    "]\n",
    "\n",
    "sentences_words = [\n",
    "    ['Human:', 'What', 'do', 'we', 'want?'],\n",
    "    ['Computer:', 'Natural', 'language', 'processing!'],\n",
    "    ['Human:', 'When', 'do', 'we', 'want', 'it?'],\n",
    "    ['Computer:', 'When', 'do', 'we', 'want', 'what?']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing source vocab\nVocab Store: Tokens [size=17],                 Characters [size=97]\nInitializing target vocab\nVocab Store: Tokens [size=17],                 Characters [size=97]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab.build(sentences, sentences_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(sentences_words, sentences_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = batch_iter(\n",
    "    data=data,\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_src, batch_tgt = next(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['Human:', 'When', 'do', 'we', 'want', 'it?'], ['Computer:', 'When', 'do', 'we', 'want', 'what?'], ['Human:', 'What', 'do', 'we', 'want?'], ['Computer:', 'Natural', 'language', 'processing!']]\n"
     ]
    }
   ],
   "source": [
    "print(batch_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[6, 6, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "source_length = [len(sent) for sent in batch_src]\n",
    "print(source_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Char Tensor size = torch.Size([6, 4, 21])\n"
     ]
    }
   ],
   "source": [
    "char_tensors = vocab.src.to_tensor(batch_src, tokens=False)\n",
    "print(f\"Char Tensor size = {char_tensors.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_embeddings: int, embedding_dim: int,\n",
    "                 char_padding_idx: int, hidden_size: int,\n",
    "                 char_embedding_dim: int = 50,\n",
    "                 num_layers: int = 2) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = CharEmbedding(\n",
    "            num_embeddings=num_embeddings,\n",
    "            char_embedding_dim=char_embedding_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            char_padding_idx=char_padding_idx\n",
    "        )\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bias=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.hidden_projection = nn.Linear(\n",
    "            in_features=hidden_size * 2,\n",
    "            out_features=hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        self.cell_projection = nn.Linear(\n",
    "            in_features=hidden_size * 2,\n",
    "            out_features=hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, source_lengths: List[int]):\n",
    "        # x is batch of sentences\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = pack_padded_sequence(x, lengths=source_lengths)\n",
    "\n",
    "        enc_output, (last_hidden, last_cell) = self.encoder(x)\n",
    "        enc_output, _ = pad_packed_sequence(enc_output)\n",
    "        enc_output = enc_output.permute([1, 0, 2])\n",
    "\n",
    "        last_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)\n",
    "        init_decoder_hidden = self.hidden_projection(last_hidden)\n",
    "\n",
    "        last_cell = torch.cat((last_cell[0], last_cell[1]), dim=1)\n",
    "        init_decoder_cell = self.cell_projection(last_cell)\n",
    "\n",
    "        return enc_output, (init_decoder_hidden, init_decoder_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    num_embeddings=vocab.src.length(tokens=False),\n",
    "    embedding_dim=300,\n",
    "    char_padding_idx=vocab.src.pad_char_idx,\n",
    "    hidden_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_enc_hidden, (char_hidden, char_cell) = encoder(char_tensors, source_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([4, 6, 2048]), torch.Size([4, 1024]), torch.Size([4, 1024]))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "char_enc_hidden.shape, char_hidden.shape, char_cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}