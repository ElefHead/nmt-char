{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from nmt.models import NMT\n",
    "from nmt.datasets import read_corpus, batch_iter, Vocab\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = Path(\"..\") / \"nmt\" / \"datasets\" / \"data\"\n",
    "en_es_data_loc = data_loc / \"en_es_data\"\n",
    "train_data_src_path = en_es_data_loc / \"train_tiny.es\"\n",
    "train_data_tgt_path = en_es_data_loc / \"train_tiny.en\"\n",
    "dev_data_src_path = en_es_data_loc / \"dev_tiny.es\"\n",
    "dev_data_tgt_path = en_es_data_loc / \"dev_tiny.en\"\n",
    "vocab_path = data_loc / \"vocab_tiny_q2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src = read_corpus(train_data_src_path)\n",
    "train_tgt = read_corpus(train_data_tgt_path, is_target=True)\n",
    "vocab = Vocab.load(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(26, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(vocab.src), len(vocab.tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hypothesis = namedtuple('Hypothesis', ['value', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_src = read_corpus(dev_data_src_path)\n",
    "valid_tgt = read_corpus(dev_data_tgt_path, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2\n",
    "MAX_EPOCH=201\n",
    "SEED=42\n",
    "EMBEDDING_SIZE=256\n",
    "HIDDEN_SIZE=256\n",
    "GRAD_CLIP=5.0\n",
    "UNIFORM_INIT=0.1\n",
    "USE_CHAR_DECODER=True\n",
    "LEARNING_RATE=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMT(\n",
    "    vocab=vocab,\n",
    "    embedding_dim=EMBEDDING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    use_char_decoder=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "uniformly initialize parameters [-0.100000, +0.100000]\n"
     ]
    }
   ],
   "source": [
    "uniform_init = UNIFORM_INIT\n",
    "if np.abs(uniform_init) > 0.:\n",
    "    print('uniformly initialize parameters [-%f, +%f]' %\n",
    "            (uniform_init, uniform_init), file=sys.stderr)\n",
    "    for p in model.parameters():\n",
    "        p.data.uniform_(-uniform_init, uniform_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [train_src[0]] ## Source sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_char_tensor = model.vocab.src.to_tensor(example, tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_encode, dec_state = model.encoder(example_char_tensor, [len(x) for x in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = [['<s>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_hypotheses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "hyp_scores = torch.zeros(\n",
    "    len(hypotheses), dtype=torch.float\n",
    ")\n",
    "print(hyp_scores.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hyps = len(hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_attention = torch.zeros(1, model.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_sent = model.vocab.tgt.end_token_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Iterating through 1 timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_prev = torch.zeros(1, model.hidden_size, device=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = model.vocab.tgt.to_tensor(\n",
    "             list([hyp[-1]] for hyp in hypotheses),\n",
    "             tokens=False, device=model.device\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 21])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_prev, dec_state, _ = model.decoder(y_t, src_encode, dec_state, o_prev, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_t = model.generator(o_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "log_p_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-3.3516, -3.5049, -3.4377, -3.5354, -3.3738, -3.4165, -3.6984, -3.4240,\n",
       "         -3.4034, -3.3990, -3.4905, -3.4608, -3.3913, -3.5046, -3.5579, -3.4502,\n",
       "         -3.4206, -3.3932, -3.5450, -3.6357, -3.4550, -3.5125, -3.3933, -3.5584,\n",
       "         -3.3560, -3.5021, -3.4387, -3.3057, -3.5281, -3.6132, -3.4817, -3.4801]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "log_p_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_hyp_num = beam_size - len(completed_hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "continuing_hyp_scores = (hyp_scores.unsqueeze(\n",
    "                1).expand_as(log_p_t) + log_p_t).view(-1)\n",
    "continuing_hyp_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cand_hyp_scores, top_cand_hyp_pos = torch.topk(\n",
    "                continuing_hyp_scores, k=live_hyp_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([-3.3057, -3.3516, -3.3560, -3.3738, -3.3913], grad_fn=<TopkBackward>),\n",
       " tensor([27,  0, 24,  4, 12]))"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "top_cand_hyp_scores, top_cand_hyp_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0, 0, 0, 0, 0]) tensor([27,  0, 24,  4, 12])\n"
     ]
    }
   ],
   "source": [
    "prev_hyp_ids = top_cand_hyp_pos / len(model.vocab.tgt)\n",
    "hyp_word_ids = top_cand_hyp_pos % len(model.vocab.tgt)\n",
    "print(prev_hyp_ids, hyp_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hypotheses = []\n",
    "live_hyp_ids = []\n",
    "new_hyp_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderStatesForUNKsHere = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prev_hyp_id, hyp_word_id, cand_new_hyp_score in zip(prev_hyp_ids, hyp_word_ids, top_cand_hyp_scores):\n",
    "    prev_hyp_id = prev_hyp_id.item()\n",
    "    hyp_word_id = hyp_word_id.item()\n",
    "    cand_new_hyp_score = cand_new_hyp_score.item()\n",
    "\n",
    "    hyp_word = model.vocab.tgt.to_tokens(hyp_word_id)\n",
    "\n",
    "    # Record output layer in case UNK was generated\n",
    "    if hyp_word == \"<unk>\":\n",
    "        hyp_word = \"<unk>\"+str(len(decoderStatesForUNKsHere))\n",
    "        decoderStatesForUNKsHere.append(o_prev[prev_hyp_id])\n",
    "\n",
    "    new_hyp_sent = hypotheses[prev_hyp_id] + [hyp_word]\n",
    "    if hyp_word == '</s>':\n",
    "        completed_hypotheses.append(Hypothesis(value=new_hyp_sent[1:-1],\n",
    "                                                score=cand_new_hyp_score))\n",
    "    else:\n",
    "        new_hypotheses.append(new_hyp_sent)\n",
    "        live_hyp_ids.append(prev_hyp_id)\n",
    "        new_hyp_scores.append(cand_new_hyp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['<s>', 'what'], ['<s>', '<pad>'], ['<s>', 'sob)'], ['<s>', 'to'], ['<s>', 'this']]\n[0, 0, 0, 0, 0]\n[-3.3057379722595215, -3.3516037464141846, -3.3559703826904297, -3.373790979385376, -3.3912715911865234]\n[]\n"
     ]
    }
   ],
   "source": [
    "print(new_hypotheses)\n",
    "print(live_hyp_ids)\n",
    "print(new_hyp_scores)\n",
    "print(completed_hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(decoderStatesForUNKsHere) > 0 and model.char_decoder is not None:  # decode UNKs\n",
    "    decoderStatesForUNKsHere = torch.stack(\n",
    "        decoderStatesForUNKsHere, dim=0)\n",
    "    decodedWords = model.greedy_char_decode((decoderStatesForUNKsHere.unsqueeze(\n",
    "        0), decoderStatesForUNKsHere.unsqueeze(0)), max_length=21)\n",
    "    assert len(decodedWords) == decoderStatesForUNKsHere.size()[\n",
    "        0], \"Incorrect number of decoded words\"\n",
    "    for hyp in new_hypotheses:\n",
    "        if hyp[-1].startswith(\"<unk>\"):\n",
    "            hyp[-1] = decodedWords[int(hyp[-1][5:])]  # [:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_hyp_ids = torch.tensor(\n",
    "    live_hyp_ids,\n",
    "    dtype=torch.long,\n",
    "    device=model.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "o_prev[live_hyp_ids].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = new_hypotheses\n",
    "hyp_scores = torch.tensor(\n",
    "    new_hyp_scores, dtype=torch.float, device=model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(completed_hypotheses) == 0:\n",
    "    completed_hypotheses.append(Hypothesis(value=hypotheses[0][1:],\n",
    "                                            score=hyp_scores[0].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_hypotheses.sort(key=lambda hyp: hyp.score, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Hypothesis(value=['what'], score=-3.3057379722595215)]"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "completed_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = new_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['<s>', 'what'],\n",
       " ['<s>', '<pad>'],\n",
       " ['<s>', 'sob)'],\n",
       " ['<s>', 'to'],\n",
       " ['<s>', 'this']]"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 000 - Cumulative loss: 76.07613372802734\n",
      "Epoch: 001 - Cumulative loss: 72.86973571777344\n",
      "Epoch: 002 - Cumulative loss: 70.12184143066406\n",
      "Epoch: 003 - Cumulative loss: 68.92034149169922\n",
      "Epoch: 004 - Cumulative loss: 66.57279968261719\n",
      "Epoch: 005 - Cumulative loss: 63.73548126220703\n",
      "Epoch: 006 - Cumulative loss: 60.94084930419922\n",
      "Epoch: 007 - Cumulative loss: 58.18658447265625\n",
      "Epoch: 008 - Cumulative loss: 54.783241271972656\n",
      "Epoch: 009 - Cumulative loss: 51.839515686035156\n",
      "Epoch: 010 - Cumulative loss: 49.84929656982422\n",
      "Epoch: 011 - Cumulative loss: 48.63710403442383\n",
      "Epoch: 012 - Cumulative loss: 47.67711639404297\n",
      "Epoch: 013 - Cumulative loss: 46.95255661010742\n",
      "Epoch: 014 - Cumulative loss: 46.43537902832031\n",
      "Epoch: 015 - Cumulative loss: 45.718360900878906\n",
      "Epoch: 016 - Cumulative loss: 45.62044906616211\n",
      "Epoch: 017 - Cumulative loss: 45.077247619628906\n",
      "Epoch: 018 - Cumulative loss: 45.197303771972656\n",
      "Epoch: 019 - Cumulative loss: 44.873931884765625\n",
      "Epoch: 020 - Cumulative loss: 44.49763107299805\n",
      "Epoch: 021 - Cumulative loss: 44.17246627807617\n",
      "Epoch: 022 - Cumulative loss: 44.04390335083008\n",
      "Epoch: 023 - Cumulative loss: 43.79682159423828\n",
      "Epoch: 024 - Cumulative loss: 43.55388641357422\n",
      "Epoch: 025 - Cumulative loss: 43.64604949951172\n",
      "Epoch: 026 - Cumulative loss: 43.67485809326172\n",
      "Epoch: 027 - Cumulative loss: 43.453773498535156\n",
      "Epoch: 028 - Cumulative loss: 43.045772552490234\n",
      "Epoch: 029 - Cumulative loss: 42.785865783691406\n",
      "Epoch: 030 - Cumulative loss: 42.658729553222656\n",
      "Epoch: 031 - Cumulative loss: 42.865604400634766\n",
      "Epoch: 032 - Cumulative loss: 42.80854034423828\n",
      "Epoch: 033 - Cumulative loss: 42.738922119140625\n",
      "Epoch: 034 - Cumulative loss: 42.31391143798828\n",
      "Epoch: 035 - Cumulative loss: 42.3955192565918\n",
      "Epoch: 036 - Cumulative loss: 42.32431411743164\n",
      "Epoch: 037 - Cumulative loss: 42.06654739379883\n",
      "Epoch: 038 - Cumulative loss: 41.61851501464844\n",
      "Epoch: 039 - Cumulative loss: 41.62251663208008\n",
      "Epoch: 040 - Cumulative loss: 41.405662536621094\n",
      "Epoch: 041 - Cumulative loss: 41.77469253540039\n",
      "Epoch: 042 - Cumulative loss: 40.98863983154297\n",
      "Epoch: 043 - Cumulative loss: 41.24388885498047\n",
      "Epoch: 044 - Cumulative loss: 40.96819305419922\n",
      "Epoch: 045 - Cumulative loss: 40.850486755371094\n",
      "Epoch: 046 - Cumulative loss: 40.634864807128906\n",
      "Epoch: 047 - Cumulative loss: 40.464508056640625\n",
      "Epoch: 048 - Cumulative loss: 40.02726364135742\n",
      "Epoch: 049 - Cumulative loss: 40.03392791748047\n",
      "Epoch: 050 - Cumulative loss: 39.91356658935547\n",
      "Epoch: 051 - Cumulative loss: 40.01373291015625\n",
      "Epoch: 052 - Cumulative loss: 39.67902755737305\n",
      "Epoch: 053 - Cumulative loss: 39.179710388183594\n",
      "Epoch: 054 - Cumulative loss: 39.218116760253906\n",
      "Epoch: 055 - Cumulative loss: 38.889625549316406\n",
      "Epoch: 056 - Cumulative loss: 38.795291900634766\n",
      "Epoch: 057 - Cumulative loss: 38.36422348022461\n",
      "Epoch: 058 - Cumulative loss: 37.88226318359375\n",
      "Epoch: 059 - Cumulative loss: 37.71110153198242\n",
      "Epoch: 060 - Cumulative loss: 37.37538528442383\n",
      "Epoch: 061 - Cumulative loss: 37.167964935302734\n",
      "Epoch: 062 - Cumulative loss: 36.788116455078125\n",
      "Epoch: 063 - Cumulative loss: 36.686317443847656\n",
      "Epoch: 064 - Cumulative loss: 36.82822036743164\n",
      "Epoch: 065 - Cumulative loss: 35.92089080810547\n",
      "Epoch: 066 - Cumulative loss: 35.97356414794922\n",
      "Epoch: 067 - Cumulative loss: 35.63054275512695\n",
      "Epoch: 068 - Cumulative loss: 35.761192321777344\n",
      "Epoch: 069 - Cumulative loss: 35.314552307128906\n",
      "Epoch: 070 - Cumulative loss: 34.98575210571289\n",
      "Epoch: 071 - Cumulative loss: 34.804649353027344\n",
      "Epoch: 072 - Cumulative loss: 34.28408432006836\n",
      "Epoch: 073 - Cumulative loss: 33.81328582763672\n",
      "Epoch: 074 - Cumulative loss: 34.07460403442383\n",
      "Epoch: 075 - Cumulative loss: 33.647743225097656\n",
      "Epoch: 076 - Cumulative loss: 33.63544845581055\n",
      "Epoch: 077 - Cumulative loss: 33.04216766357422\n",
      "Epoch: 078 - Cumulative loss: 32.53147888183594\n",
      "Epoch: 079 - Cumulative loss: 32.525413513183594\n",
      "Epoch: 080 - Cumulative loss: 32.273414611816406\n",
      "Epoch: 081 - Cumulative loss: 31.98406410217285\n",
      "Epoch: 082 - Cumulative loss: 31.693761825561523\n",
      "Epoch: 083 - Cumulative loss: 31.24909019470215\n",
      "Epoch: 084 - Cumulative loss: 31.091007232666016\n",
      "Epoch: 085 - Cumulative loss: 30.78093910217285\n",
      "Epoch: 086 - Cumulative loss: 30.279499053955078\n",
      "Epoch: 087 - Cumulative loss: 30.10207176208496\n",
      "Epoch: 088 - Cumulative loss: 29.78579330444336\n",
      "Epoch: 089 - Cumulative loss: 29.603445053100586\n",
      "Epoch: 090 - Cumulative loss: 29.227651596069336\n",
      "Epoch: 091 - Cumulative loss: 28.71602439880371\n",
      "Epoch: 092 - Cumulative loss: 28.744388580322266\n",
      "Epoch: 093 - Cumulative loss: 28.318370819091797\n",
      "Epoch: 094 - Cumulative loss: 28.13034439086914\n",
      "Epoch: 095 - Cumulative loss: 27.544692993164062\n",
      "Epoch: 096 - Cumulative loss: 27.851119995117188\n",
      "Epoch: 097 - Cumulative loss: 27.583755493164062\n",
      "Epoch: 098 - Cumulative loss: 27.112621307373047\n",
      "Epoch: 099 - Cumulative loss: 26.458581924438477\n",
      "Epoch: 100 - Cumulative loss: 26.54180908203125\n",
      "Epoch: 101 - Cumulative loss: 25.75118637084961\n",
      "Epoch: 102 - Cumulative loss: 25.34353256225586\n",
      "Epoch: 103 - Cumulative loss: 25.361553192138672\n",
      "Epoch: 104 - Cumulative loss: 25.00359344482422\n",
      "Epoch: 105 - Cumulative loss: 24.64025115966797\n",
      "Epoch: 106 - Cumulative loss: 24.52005958557129\n",
      "Epoch: 107 - Cumulative loss: 24.177249908447266\n",
      "Epoch: 108 - Cumulative loss: 23.2813777923584\n",
      "Epoch: 109 - Cumulative loss: 23.34691619873047\n",
      "Epoch: 110 - Cumulative loss: 23.291486740112305\n",
      "Epoch: 111 - Cumulative loss: 22.68722152709961\n",
      "Epoch: 112 - Cumulative loss: 22.626049041748047\n",
      "Epoch: 113 - Cumulative loss: 22.373815536499023\n",
      "Epoch: 114 - Cumulative loss: 22.174942016601562\n",
      "Epoch: 115 - Cumulative loss: 21.768198013305664\n",
      "Epoch: 116 - Cumulative loss: 21.400388717651367\n",
      "Epoch: 117 - Cumulative loss: 21.059303283691406\n",
      "Epoch: 118 - Cumulative loss: 21.33647346496582\n",
      "Epoch: 119 - Cumulative loss: 20.92081069946289\n",
      "Epoch: 120 - Cumulative loss: 20.5087947845459\n",
      "Epoch: 121 - Cumulative loss: 19.911190032958984\n",
      "Epoch: 122 - Cumulative loss: 19.8032283782959\n",
      "Epoch: 123 - Cumulative loss: 20.339174270629883\n",
      "Epoch: 124 - Cumulative loss: 19.47355079650879\n",
      "Epoch: 125 - Cumulative loss: 19.637975692749023\n",
      "Epoch: 126 - Cumulative loss: 19.14754867553711\n",
      "Epoch: 127 - Cumulative loss: 19.45750617980957\n",
      "Epoch: 128 - Cumulative loss: 18.979108810424805\n",
      "Epoch: 129 - Cumulative loss: 18.497190475463867\n",
      "Epoch: 130 - Cumulative loss: 18.669639587402344\n",
      "Epoch: 131 - Cumulative loss: 17.716386795043945\n",
      "Epoch: 132 - Cumulative loss: 17.51961326599121\n",
      "Epoch: 133 - Cumulative loss: 16.994417190551758\n",
      "Epoch: 134 - Cumulative loss: 17.18729591369629\n",
      "Epoch: 135 - Cumulative loss: 16.582538604736328\n",
      "Epoch: 136 - Cumulative loss: 16.567211151123047\n",
      "Epoch: 137 - Cumulative loss: 16.502552032470703\n",
      "Epoch: 138 - Cumulative loss: 16.062353134155273\n",
      "Epoch: 139 - Cumulative loss: 15.736589431762695\n",
      "Epoch: 140 - Cumulative loss: 15.629353523254395\n",
      "Epoch: 141 - Cumulative loss: 15.045814514160156\n",
      "Epoch: 142 - Cumulative loss: 14.737236022949219\n",
      "Epoch: 143 - Cumulative loss: 14.51249885559082\n",
      "Epoch: 144 - Cumulative loss: 14.32489013671875\n",
      "Epoch: 145 - Cumulative loss: 14.022796630859375\n",
      "Epoch: 146 - Cumulative loss: 13.923113822937012\n",
      "Epoch: 147 - Cumulative loss: 13.691632270812988\n",
      "Epoch: 148 - Cumulative loss: 13.562207221984863\n",
      "Epoch: 149 - Cumulative loss: 13.062118530273438\n",
      "Epoch: 150 - Cumulative loss: 12.815078735351562\n",
      "Epoch: 151 - Cumulative loss: 12.671404838562012\n",
      "Epoch: 152 - Cumulative loss: 12.108381271362305\n",
      "Epoch: 153 - Cumulative loss: 12.353281021118164\n",
      "Epoch: 154 - Cumulative loss: 12.15241813659668\n",
      "Epoch: 155 - Cumulative loss: 11.253725051879883\n",
      "Epoch: 156 - Cumulative loss: 11.0831937789917\n",
      "Epoch: 157 - Cumulative loss: 11.218706130981445\n",
      "Epoch: 158 - Cumulative loss: 10.933172225952148\n",
      "Epoch: 159 - Cumulative loss: 10.448931694030762\n",
      "Epoch: 160 - Cumulative loss: 10.283258438110352\n",
      "Epoch: 161 - Cumulative loss: 10.023554801940918\n",
      "Epoch: 162 - Cumulative loss: 9.825702667236328\n",
      "Epoch: 163 - Cumulative loss: 9.702134132385254\n",
      "Epoch: 164 - Cumulative loss: 9.186502456665039\n",
      "Epoch: 165 - Cumulative loss: 8.933568954467773\n",
      "Epoch: 166 - Cumulative loss: 8.6932954788208\n",
      "Epoch: 167 - Cumulative loss: 8.381523132324219\n",
      "Epoch: 168 - Cumulative loss: 8.16711139678955\n",
      "Epoch: 169 - Cumulative loss: 8.267033576965332\n",
      "Epoch: 170 - Cumulative loss: 7.883256435394287\n",
      "Epoch: 171 - Cumulative loss: 7.868075370788574\n",
      "Epoch: 172 - Cumulative loss: 7.702378273010254\n",
      "Epoch: 173 - Cumulative loss: 7.671651363372803\n",
      "Epoch: 174 - Cumulative loss: 7.142159461975098\n",
      "Epoch: 175 - Cumulative loss: 7.1970062255859375\n",
      "Epoch: 176 - Cumulative loss: 6.727875709533691\n",
      "Epoch: 177 - Cumulative loss: 6.608648777008057\n",
      "Epoch: 178 - Cumulative loss: 6.385022163391113\n",
      "Epoch: 179 - Cumulative loss: 6.4313645362854\n",
      "Epoch: 180 - Cumulative loss: 6.083072185516357\n",
      "Epoch: 181 - Cumulative loss: 5.966686725616455\n",
      "Epoch: 182 - Cumulative loss: 5.871701240539551\n",
      "Epoch: 183 - Cumulative loss: 6.126413822174072\n",
      "Epoch: 184 - Cumulative loss: 5.6592631340026855\n",
      "Epoch: 185 - Cumulative loss: 5.3614726066589355\n",
      "Epoch: 186 - Cumulative loss: 5.274264335632324\n",
      "Epoch: 187 - Cumulative loss: 4.854485511779785\n",
      "Epoch: 188 - Cumulative loss: 4.911473751068115\n",
      "Epoch: 189 - Cumulative loss: 5.208830833435059\n",
      "Epoch: 190 - Cumulative loss: 4.695879936218262\n",
      "Epoch: 191 - Cumulative loss: 4.6619062423706055\n",
      "Epoch: 192 - Cumulative loss: 4.498806953430176\n",
      "Epoch: 193 - Cumulative loss: 4.166779041290283\n",
      "Epoch: 194 - Cumulative loss: 4.314126968383789\n",
      "Epoch: 195 - Cumulative loss: 4.162171363830566\n",
      "Epoch: 196 - Cumulative loss: 4.081435203552246\n",
      "Epoch: 197 - Cumulative loss: 3.7608158588409424\n",
      "Epoch: 198 - Cumulative loss: 3.8207366466522217\n",
      "Epoch: 199 - Cumulative loss: 3.4808731079101562\n",
      "Epoch: 200 - Cumulative loss: 3.723270893096924\n",
      "CPU times: user 9min 27s, sys: 4.61 s, total: 9min 32s\n",
      "Wall time: 49.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    cum_loss = 0\n",
    "    for i, (src_sents, tgt_sents) in enumerate(batch_iter((train_src, train_tgt), batch_size=BATCH_SIZE, shuffle=True)):\n",
    "        optimizer.zero_grad()\n",
    "        batch_size = len(src_sents)\n",
    "\n",
    "        batch_loss = -model(src_sents, tgt_sents).sum()\n",
    "        batch_loss /= batch_size\n",
    "        cum_loss += batch_loss\n",
    "        batch_loss.backward()\n",
    "\n",
    "         # clip gradient\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "    cum_loss /= len(train_src)\n",
    "    print(f\"Epoch: {str(epoch).zfill(3)} - Cumulative loss: {cum_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nmt.scripts import beam_search_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = beam_search_decoder(\n",
    "    model=model,\n",
    "    src_sent=train_src[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Hypothesis(value=['anthe', 'quedado', 'conmovido', 'por', 'confer', 'esta', 'y', 'conferencia,', 'deseo', 'a', 'agradece', 'todos', 'a', 'ustados', 'de', 'denado', 'de', 'de', 'lo', 'lo', 'que', 'que', 'que', 'que', 'que', 'decir', 'decir', 'lo', 'noche.', 'noche.', 'noche', 'noche.', 'que', 'noche.', 'ncenthe', 'nicer', 'coment', 'naca', 'niche', 'noche.', 'que', 'niche', 'niche.', 'niche.', 'niche', 'noche.', 'niche', 'noche.', 'nicer', 'noche.', 'noche.', 'noche.', 'noche.', 'noche.', 'noche.', 'niche.', 'noche.', 'niche.', 'noche.', 'nicer', 'niche.', 'nicer', 'noche.', 'nicer', 'niche.', 'niche.', 'niche.', 'niche.', 'noche.', 'noche.'], score=-1.1814473867416382)]"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}