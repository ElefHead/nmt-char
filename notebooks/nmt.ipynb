{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from nmt.networks import Encoder, Decoder, CharDecoder\n",
    "from nmt.datasets import Vocab\n",
    "from nmt.layers import Generator\n",
    "from nmt.datasets import batch_iter"
   ]
  },
  {
   "source": [
    "The goal in this notebook is to sort of recreate assignment 4. We have almost everything required. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT(nn.Module):\n",
    "    def __init__(self, vocab: Vocab,\n",
    "                 embedding_dim: int,\n",
    "                 hidden_size: int,\n",
    "                 num_encoder_layers: int = 2,\n",
    "                 use_char_decoder: bool = False) -> None:\n",
    "        super(NMT, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.encoder = Encoder(\n",
    "            num_embeddings=vocab.src.length(tokens=False),\n",
    "            embedding_dim=embedding_dim,\n",
    "            char_padding_idx=vocab.src.pad_char_idx,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_encoder_layers\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            num_embeddings=vocab.tgt.length(tokens=False),\n",
    "            embedding_dim=embedding_dim,\n",
    "            char_padding_idx=vocab.tgt.pad_char_idx,\n",
    "            hidden_size=hidden_size\n",
    "        )\n",
    "        self.generator = Generator(\n",
    "            in_features=hidden_size,\n",
    "            out_features=len(vocab.tgt)\n",
    "        )\n",
    "        self.char_decoder = None\n",
    "        if use_char_decoder:\n",
    "            self.char_decoder = CharDecoder(\n",
    "                num_embeddings=vocab.tgt.length(tokens=False),\n",
    "                hidden_size=hidden_size,\n",
    "                padding_idx=vocab.tgt.pad_char_idx\n",
    "            )\n",
    "        self.hidden_size = hidden_size\n",
    "        self.current_device = None\n",
    "\n",
    "    def forward(self,\n",
    "                x: List[List[int]],\n",
    "                y: List[List[int]],\n",
    "                training: bool = False) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        src_length = [len(sent) for sent in x]\n",
    "\n",
    "        src_tensor = self.vocab.src.to_tensor(\n",
    "            x, tokens=False, device=self.device\n",
    "        )\n",
    "        tgt_tensor = self.vocab.tgt.to_tensor(\n",
    "            y, tokens=False, device=self.device\n",
    "        )\n",
    "        tgt_token_tensor = self.vocab.tgt.to_tensor(\n",
    "            y, tokens=True, device=self.device\n",
    "        )\n",
    "\n",
    "        tgt_tensor_noend = tgt_tensor[:-1]\n",
    "        src_encoding, dec_state = self.encoder(src_tensor, src_length)\n",
    "\n",
    "        enc_masks = self.generate_sentence_masks(src_encoding, src_length)\n",
    "\n",
    "        batch_size, _, _ = src_encoding.size()\n",
    "\n",
    "        o_prev = torch.zeros(batch_size, self.hidden_size, device=self.device)\n",
    "\n",
    "        combined_outputs = []\n",
    "        for y_t in torch.split(tgt_tensor_noend, 1, dim=0):\n",
    "            o_prev, dec_state, _ = self.decoder(\n",
    "                y_t, src_encoding, dec_state, o_prev, enc_masks)\n",
    "            combined_outputs.append(o_prev)\n",
    "\n",
    "        combined_outputs = torch.stack(combined_outputs, dim=0)\n",
    "\n",
    "        probs = self.generator(combined_outputs)\n",
    "\n",
    "        # zero out the pad targets\n",
    "        target_masks = (tgt_token_tensor != self.vocab.tgt['<pad>']).float()\n",
    "\n",
    "        # Compute log probability of generating true target words\n",
    "        target_token_log_prob = torch.gather(\n",
    "            probs, index=tgt_token_tensor[1:].unsqueeze(-1), dim=-1\n",
    "        ).squeeze(-1) * target_masks[1:]\n",
    "\n",
    "        loss = target_token_log_prob.sum()\n",
    "\n",
    "        if self.char_decoder:\n",
    "            max_word_len = tgt_tensor.shape[-1]\n",
    "            target_chars = tgt_tensor[1:].contiguous().view(-1, max_word_len)\n",
    "            target_outputs = combined_outputs.view(-1, self.hidden_size)\n",
    "\n",
    "            target_chars_oov = target_chars.t()\n",
    "            rnn_states_oov = target_outputs.unsqueeze(0)\n",
    "\n",
    "            char_logits, char_dec_state = self.char_decoder(\n",
    "                target_chars_oov[:-1],\n",
    "                (rnn_states_oov, rnn_states_oov)\n",
    "            )\n",
    "\n",
    "            char_logits = char_logits.view(-1, char_logits.shape[-1])\n",
    "            target_chars_oov = target_chars_oov[1:].contiguous().view(-1)\n",
    "\n",
    "            char_loss = nn.CrossEntropyLoss(\n",
    "                reduction=\"sum\",\n",
    "                ignore_index=self.vocab.tgt.pad_char_idx\n",
    "            )\n",
    "\n",
    "            loss = loss - char_loss(char_logits, target_chars_oov)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def generate_sentence_masks(self,\n",
    "                                enc_out: torch.Tensor,\n",
    "                                source_lengths: List[int]) -> torch.Tensor:\n",
    "        enc_masks = torch.zeros(\n",
    "            enc_out.size(0),\n",
    "            enc_out.size(1),\n",
    "            device=self.device\n",
    "        )\n",
    "        for e_id, src_len in enumerate(source_lengths):\n",
    "            enc_masks[e_id, src_len:] = 1\n",
    "        return enc_masks\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        if not self.current_device:\n",
    "            self.current_device = next(self.parameters()).device\n",
    "        return self.current_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_words_src = [\n",
    "    ['Human:', 'What', 'do', 'we', 'want?'],\n",
    "    ['Computer:', 'Natural', 'language', 'processing!'],\n",
    "    ['Human:', 'When', 'do', 'we', 'want', 'it?'],\n",
    "    ['Computer:', 'When', 'do', 'we', 'want', 'what?']\n",
    "]\n",
    "\n",
    "sentences_words_tgt = [\n",
    "    ['<s>', 'Human:', 'What', 'do', 'we', 'want?', '</s>'],\n",
    "    ['<s>', 'Computer:', 'Natural', 'language', 'processing!', '</s>'],\n",
    "    ['<s>', 'Human:', 'When', 'do', 'we', 'want', 'it?', '</s>'],\n",
    "    ['<s>', 'Computer:', 'When', 'do', 'we', 'want', 'what?', '</s>']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing source vocab\nVocab Store: Tokens [size=17],                 Characters [size=97]\nInitializing target vocab\nVocab Store: Tokens [size=17],                 Characters [size=97]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab.build(sentences_words_src, sentences_words_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(sentences_words_src, sentences_words_tgt))\n",
    "data_generator = batch_iter(\n",
    "    data=data,\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")\n",
    "batch_src, batch_tgt = next(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMT(\n",
    "    vocab=vocab, \n",
    "    embedding_dim=300,\n",
    "    hidden_size=1024\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(batch_src, batch_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(-70.8261, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_char = NMT(\n",
    "    vocab=vocab, \n",
    "    embedding_dim=300,\n",
    "    hidden_size=1024,\n",
    "    use_char_decoder=True\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_char = model(batch_src, batch_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(-70.8072, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "len(list(model_char.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}