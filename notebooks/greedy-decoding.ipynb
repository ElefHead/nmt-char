{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from nmt.models import NMT\n",
    "from nmt.datasets import read_corpus, batch_iter, Vocab\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = Path(\"..\") / \"nmt\" / \"datasets\" / \"data\"\n",
    "en_es_data_loc = data_loc / \"en_es_data\"\n",
    "train_data_src_path = en_es_data_loc / \"train_tiny.es\"\n",
    "train_data_tgt_path = en_es_data_loc / \"train_tiny.en\"\n",
    "dev_data_src_path = en_es_data_loc / \"dev_tiny.es\"\n",
    "dev_data_tgt_path = en_es_data_loc / \"dev_tiny.en\"\n",
    "vocab_path = data_loc / \"vocab_tiny_q2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src = read_corpus(train_data_src_path)\n",
    "train_tgt = read_corpus(train_data_tgt_path, is_target=True)\n",
    "vocab = Vocab.load(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(26, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(vocab.src), len(vocab.tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_src = read_corpus(dev_data_src_path)\n",
    "valid_tgt = read_corpus(dev_data_tgt_path, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2\n",
    "MAX_EPOCH=201\n",
    "SEED=42\n",
    "EMBEDDING_SIZE=256\n",
    "HIDDEN_SIZE=256\n",
    "GRAD_CLIP=5.0\n",
    "UNIFORM_INIT=0.1\n",
    "USE_CHAR_DECODER=True\n",
    "LEARNING_RATE=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMT(\n",
    "    vocab=vocab,\n",
    "    embedding_dim=EMBEDDING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    use_char_decoder=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NMT(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): CharEmbedding(\n",
       "      (char_embed): Embedding(97, 50, padding_idx=0)\n",
       "      (cnn_embed): CharCNNEmbedding(\n",
       "        (conv): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
       "        (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "      )\n",
       "      (highway): Highway(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (gate): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (encoder): LSTM(256, 256, num_layers=2, bidirectional=True)\n",
       "    (hidden_projection): Linear(in_features=512, out_features=256, bias=False)\n",
       "    (cell_projection): Linear(in_features=512, out_features=256, bias=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): CharEmbedding(\n",
       "      (char_embed): Embedding(97, 50, padding_idx=0)\n",
       "      (cnn_embed): CharCNNEmbedding(\n",
       "        (conv): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
       "        (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "      )\n",
       "      (highway): Highway(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (gate): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (attention): Attention(\n",
       "      (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "    )\n",
       "    (decoder): LSTMCell(512, 256)\n",
       "    (combined_projection): Linear(in_features=768, out_features=256, bias=False)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (target_layer): Linear(in_features=256, out_features=32, bias=False)\n",
       "  (char_decoder): CharDecoder(\n",
       "    (embedding): Embedding(97, 50, padding_idx=0)\n",
       "    (char_decoder): LSTM(50, 256)\n",
       "    (linear): Linear(in_features=256, out_features=97, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "uniformly initialize parameters [-0.100000, +0.100000]\n"
     ]
    }
   ],
   "source": [
    "uniform_init = UNIFORM_INIT\n",
    "if np.abs(uniform_init) > 0.:\n",
    "    print('uniformly initialize parameters [-%f, +%f]' %\n",
    "            (uniform_init, uniform_init), file=sys.stderr)\n",
    "    for p in model.parameters():\n",
    "        p.data.uniform_(-uniform_init, uniform_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 9min 39s, sys: 5 s, total: 9min 44s\nWall time: 51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    cum_loss = 0\n",
    "    for i, (src_sents, tgt_sents) in enumerate(batch_iter((train_src, train_tgt), batch_size=BATCH_SIZE, shuffle=True)):\n",
    "        optimizer.zero_grad()\n",
    "        batch_size = len(src_sents)\n",
    "\n",
    "        batch_loss = -model(src_sents, tgt_sents).sum()\n",
    "        batch_loss /= batch_size\n",
    "        cum_loss += batch_loss\n",
    "        batch_loss.backward()\n",
    "\n",
    "         # clip gradient\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "    cum_loss /= len(train_src)\n",
    "    print(f\"Epoch: {str(epoch).zfill(3)} - Cumulative loss: {cum_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NMT(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): CharEmbedding(\n",
       "      (char_embed): Embedding(97, 50, padding_idx=0)\n",
       "      (cnn_embed): CharCNNEmbedding(\n",
       "        (conv): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
       "        (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "      )\n",
       "      (highway): Highway(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (gate): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (encoder): LSTM(256, 256, num_layers=2, bidirectional=True)\n",
       "    (hidden_projection): Linear(in_features=512, out_features=256, bias=False)\n",
       "    (cell_projection): Linear(in_features=512, out_features=256, bias=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): CharEmbedding(\n",
       "      (char_embed): Embedding(97, 50, padding_idx=0)\n",
       "      (cnn_embed): CharCNNEmbedding(\n",
       "        (conv): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
       "        (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "      )\n",
       "      (highway): Highway(\n",
       "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (gate): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (attention): Attention(\n",
       "      (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "    )\n",
       "    (decoder): LSTMCell(512, 256)\n",
       "    (combined_projection): Linear(in_features=768, out_features=256, bias=False)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (target_layer): Linear(in_features=256, out_features=32, bias=False)\n",
       "  (char_decoder): CharDecoder(\n",
       "    (embedding): Embedding(97, 50, padding_idx=0)\n",
       "    (char_decoder): LSTM(50, 256)\n",
       "    (linear): Linear(in_features=256, out_features=97, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['Muchas', 'gracias', 'Chris.', 'Y', 'es', 'en', 'verdad', 'un', 'gran', 'honor', 'tener', 'la', 'oportunidad', 'de', 'venir', 'a', 'este', 'escenario', 'por', 'segunda', 'vez.', 'Estoy', 'extremadamente', 'agradecido.']] [24]\n"
     ]
    }
   ],
   "source": [
    "example = [valid_src[0]]\n",
    "example_length = [len(e) for e in example]\n",
    "print(example, example_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_token_tensor = vocab.src.to_tensor(example, tokens=True)\n",
    "example_char_tensor = vocab.src.to_tensor(example, tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([24, 1, 21]), torch.Size([24, 1]))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "example_char_tensor.shape, example_token_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out, enc_state = model.encoder(example_char_tensor, example_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 512])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "enc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_state = enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = vocab.tgt.to_tensor([[\"<s>\"]], tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.zeros(1, model.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, dec_state, _ = model.decoder(y_t, enc_out, dec_state, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.target_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = out.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "vocab.tgt.to_tokens(index)"
   ]
  },
  {
   "source": [
    "## Bringing it all together"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_char_tensor = vocab.src.to_tensor(example, tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out, enc_state = model.encoder(example_char_tensor, example_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"<s>\"\n",
    "out = torch.zeros(1, model.hidden_size)\n",
    "sent = []\n",
    "combined_out = []\n",
    "for i in range(40):\n",
    "    y_t = vocab.tgt.to_tensor([[token]], tokens=False)\n",
    "    out, dec_state, _ = model.decoder(y_t, enc_out, dec_state, out)\n",
    "    combined_out.append(out)\n",
    "    logit = model.target_layer(out)\n",
    "    index = logit.argmax().item()\n",
    "    if index == vocab.tgt.end_token_idx:\n",
    "        break\n",
    "    token = vocab.tgt.to_tokens(index)\n",
    "    sent.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>']"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}